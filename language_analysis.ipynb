{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbe3040",
   "metadata": {},
   "source": [
    "Author: Mateusz Burza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e702b",
   "metadata": {},
   "source": [
    "## Implementation of function `lang_confidence_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_confidence_score(word_counts: dict,\n",
    "                            language_words_with_frequency: dict) -> float:\n",
    "    \"\"\"\n",
    "    Given a dictionary of word counts and a dictionary of language words\n",
    "    with their frequencies, return a confidence score in [0, 1]\n",
    "    indicating how well the text matches the language distribution.\n",
    "    \"\"\"\n",
    "    if not word_counts or not language_words_with_frequency:\n",
    "        return 0.0\n",
    "\n",
    "    total = sum(word_counts.values())\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # `word_counts` should be normalised\n",
    "    article_freqs = {w: c / total for w, c in word_counts.items()}\n",
    "\n",
    "    # Language frequencies as provided (assumed normalized by wordfreq)\n",
    "    lang_freqs = language_words_with_frequency\n",
    "    k = len(lang_freqs)\n",
    "    if k == 0:\n",
    "        return 0.0\n",
    "\n",
    "    overlap = set(article_freqs.keys()) & set(lang_freqs.keys())\n",
    "    comb_size = (len(article_freqs) + len(lang_freqs)) / 2\n",
    "    overlap_ratio = len(overlap) / comb_size\n",
    "\n",
    "    if not overlap:\n",
    "        return 0.0\n",
    "\n",
    "    # Frequency difference: how well do article frequencies match language frequencies?\n",
    "    eps = 1e-9\n",
    "    diffs = [abs((article_freqs[w] + eps) - (lang_freqs[w] + eps)) for w in overlap]\n",
    "    avg_diff = sum(diffs) / len(diffs)\n",
    "    \n",
    "    # Convert difference to similarity: lower difference = higher score\n",
    "    freq_similarity = max(0.0, 1.0 - avg_diff)\n",
    "\n",
    "    # Confidence penalty for small overlaps - avoid false positives with few common words\n",
    "    overlap_confidence = min(1.0, len(overlap) / (k * 5))\n",
    "    if len(overlap) > 50:\n",
    "        overlap_confidence = 1.0\n",
    "\n",
    "    score = 0.4 * overlap_ratio + (0.6 * freq_similarity * overlap_confidence)\n",
    "\n",
    "     # Apply logistic function to smooth the score\n",
    "    from math import exp\n",
    "    logistic_score = 1.0 / (1.0 + exp(-(score - 0.5) * 10))\n",
    "\n",
    "    return logistic_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813f2c9",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce83f96",
   "metadata": {},
   "source": [
    "Collect data from wiki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48755024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "from json import load\n",
    "\n",
    "big_path = Path(\"/content/wiki_big_article_wc.json\")\n",
    "low_path = Path(\"/content/wiki_low_conf_score_wc.json\")\n",
    "\n",
    "# appropriate dicts should be in these files\n",
    "uploaded = files.upload()\n",
    "\n",
    "with big_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    big_article_wc = load(f)\n",
    "\n",
    "with low_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    low_conf_score_wc = load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe25c5",
   "metadata": {},
   "source": [
    "Second data source: FrequencyWords (https://github.com/hermitdave/FrequencyWords),\n",
    "licensed under CC BY-SA 4.0.\n",
    "\n",
    "Used for statistical analysis only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd20eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "def load_freq(lang, n=10_000):\n",
    "    \"\"\"Load frequency list from GitHub FrequencyWords repository\"\"\"\n",
    "    try:\n",
    "        url = f\"https://raw.githubusercontent.com/hermitdave/FrequencyWords/master/content/2018/{lang}/{lang}_50k.txt\"\n",
    "        df = read_csv(\n",
    "            url,\n",
    "            sep=\" \",\n",
    "            names=[\"word\", \"frequency\"]\n",
    "        )\n",
    "        return df.head(n)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading frequency data for {lang}: {e}\")\n",
    "        return None\n",
    "\n",
    "def normalize_to_dict(df):\n",
    "    if df is None:\n",
    "        return {}\n",
    "    total = df[\"frequency\"].sum()\n",
    "    return dict(zip(df[\"word\"], df[\"frequency\"] / total))\n",
    "\n",
    "langs = [\"en\", \"de\", \"es\"]\n",
    "\n",
    "external_wc = {}\n",
    "for lang in langs:\n",
    "    df = load_freq(lang)\n",
    "    external_wc[lang] = normalize_to_dict(df)\n",
    "    if external_wc[lang]:\n",
    "        print(f\"Loaded {len(external_wc[lang])} words for {lang}\")\n",
    "    else:\n",
    "        print(f\"Failed to load data for {lang}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f90685",
   "metadata": {},
   "source": [
    "Collect data from `wordfreq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc58e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordfreq\n",
    "from wordfreq import top_n_list, word_frequency\n",
    "\n",
    "# Helper function: build dict of top-k words with their language frequencies\n",
    "def build_language_freq(language: str, k: int) -> dict:\n",
    "    words = top_n_list(language, k)\n",
    "    return {w: word_frequency(w, language) for w in words}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9abd06",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [3, 10, 100, 1000]\n",
    "langs = [(\"English\", \"en\"), (\"Spanish\", \"es\"), (\"German\", \"de\")]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "word_counts_dict = {\n",
    "    \"low_conf\": low_conf_score_wc,\n",
    "    \"big_article\": big_article_wc,\n",
    "    \"external_en\": external_wc[\"en\"],\n",
    "    \"external_de\": external_wc[\"de\"],\n",
    "    \"external_es\": external_wc[\"es\"],\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 5))\n",
    "\n",
    "for idx, (lang_name, lang_code) in enumerate(langs):\n",
    "    ax = axes[idx]\n",
    "    for label, wc in word_counts_dict.items():\n",
    "        scores = []\n",
    "        for k in k_values:\n",
    "            lang_freq = build_language_freq(lang_code, k)\n",
    "            s = lang_confidence_score(wc, lang_freq)\n",
    "            scores.append(s)\n",
    "        scores_for_plot = [s for s in scores]\n",
    "        ax.plot(k_values, scores_for_plot, marker=\"o\", label=label)\n",
    "    ax.set_title(f\"Lang. confidence vs k ({lang_name})\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"k values\")\n",
    "    ax.set_ylabel(\"Confidence\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87630a2",
   "metadata": {},
   "source": [
    "## Description of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17bcca",
   "metadata": {},
   "source": [
    "### Did the choice of languages have an impact on the confidence scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2b9dd",
   "metadata": {},
   "source": [
    "It had an impact. English and German come from the same language family - Germanic, and moreover, they generally originate from a geographically similar region. The graphs clearly show that in these languages there are many mutual borrowings and many popular common words (which is only amplified by, for example, similar culture).\n",
    "\n",
    "In summary, the choice of languages had a significant impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758bcf05",
   "metadata": {},
   "source": [
    "### Looking at the `language_words_with_frequency` values for the data and the most frequent words in the language of the data, can your see that in the selected language words are often inflected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbf2c7",
   "metadata": {},
   "source": [
    "You can see that these words do not have many inflections (unlike, for example, in Polish).\n",
    "\n",
    "Something else stands out:\n",
    "-> the vocabulary used in the wiki is quite niche\n",
    "\n",
    "This is visible in the first chart - as `k` increases, the `lang_confidence_score` function clearly trends downward.\n",
    "This means that beyond the set of the most popular words (which sometimes appear as loanwords in other languages), the wiki articles contain words that are not popular. Given the specificity of this wiki (Pokemon and the whole universe), I consider this an expected result.\n",
    "\n",
    "The second and third charts show that the overlap between the compared languages and the Englishâ€“wiki word sets differs noticeably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1fb56",
   "metadata": {},
   "source": [
    "### Was it difficult to find and article for which the `lang_confidence_score` result is as low as possible in the wiki? Is this a specificity of this wiki?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c06e8f5",
   "metadata": {},
   "source": [
    "Yes and no.\n",
    "\n",
    "For the value of this function to be simply low? -> Yes\n",
    "That mainly follows from what I described in the previous answer.\n",
    "\n",
    "For it to be the lowest possible? -> That took a bit of work.\n",
    "\n",
    "However, the differences were not huge. (maybe we need to add a new page to the wiki ;)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
